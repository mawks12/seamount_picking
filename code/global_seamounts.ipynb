{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from smount_predictors.src.SeamountHelp import PipelinePredictor\n",
    "from smount_predictors import SeamountHelp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplekml\n",
    "import xarray as xr\n",
    "from interfaces_exclude.exclude_interface import exclude_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! gmt grdmath dist2coast.grd 20 GE = coast_mask.grd\n",
    "! gmt grdmath depth_mask.grd coast_mask.grd MUL = swot_mask.grd\n",
    "! gmt grdmath swot_mask.grd vgg_swot.grd MUL = swot_landmask.grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_pairs = []\n",
    "for lon in range(-180, 180, 5):\n",
    "    longitude_pairs.append((lon, lon + 5))\n",
    "\n",
    "latitude_pairs = []\n",
    "for lat in range(-80, 80, 5):\n",
    "    latitude_pairs.append((lat, lat + 5))\n",
    "\n",
    "latlons = list(product(longitude_pairs, latitude_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('out/3d_model.pkl', 'rb'))\n",
    "data_p = Path('data/swot_landmask.grd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model not trained, so set C=1, and sigma=0.9706\n",
    "\n",
    "C = 1\n",
    "sigma = 0.9706\n",
    "\n",
    "model.model.named_steps['predictor'].C_ = C\n",
    "model.model.named_steps['trans'].sigma = sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SeamountHelp.readAndFilterGRD(Path('buffer/training_data_new.nc'))\n",
    "X = data.to_dataframe().reset_index()[['lon', 'lat', 'z']]\n",
    "y = data.to_dataframe().reset_index()['Labels']\n",
    "model.model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster(model: PipelinePredictor, predictions: pd.DataFrame):\n",
    "    def filter_clust_size(data: pd.DataFrame):\n",
    "        def circle_ratio(data: pd.DataFrame):\n",
    "            if abs(data['lon'].max() - data['lon'].min()) == 0:\n",
    "                return 0\n",
    "            if data.loc[:, 'cluster'].mean() == -1:\n",
    "                return 1\n",
    "            circle = abs(data['lat'].max() - data['lat'].min()) / abs(data['lon'].max() - data['lon'].min())\n",
    "            mass = (abs(data['lat'].max() - data['lat'].min()) * abs(data['lon'].max() - data['lon'].min())) / data.shape[0]\n",
    "            if circle == 0:\n",
    "                return 0\n",
    "            mass = 4 * mass / (circle * np.pi)  # Scale mass to be 1 if it is the correct mass of a circle\n",
    "            return circle * mass\n",
    "        circle_range = data\n",
    "        divs = circle_range.groupby('cluster').apply(circle_ratio)\n",
    "        divs = divs[(divs > np.mean(divs) - np.std(divs)) & (divs < np.mean(divs) + np.std(divs))]\n",
    "        circle_range = circle_range.loc[(~circle_range['cluster'].isin(divs.index)) & (circle_range['cluster'] != -1)]\n",
    "        return circle_range\n",
    "\n",
    "    def norm_z(data: pd.DataFrame):\n",
    "        data['norm_z'] = (data['z'] - data['z'].min()) / (data['z'].max() - data['z'].min())\n",
    "        return data\n",
    "    predictions = predictions.reset_index()\n",
    "    clust_filt = predictions.copy()\n",
    "\n",
    "    clust_filt = filter_clust_size(clust_filt)\n",
    "    clust_filt = norm_z(clust_filt)\n",
    "    recluster_index = (clust_filt['cluster'] != -1) & (clust_filt['norm_z'] > 0.7)\n",
    "    clust_pred = clust_filt.loc[recluster_index]\n",
    "\n",
    "    model.clusterer.fit_predict(clust_pred[['lon', 'lat']])\n",
    "    clust_filt.loc[recluster_index, 'cluster'] = model.clusterer.labels_ + predictions['cluster'].max() + 1\n",
    "    clust_filt.loc[~recluster_index, 'cluster'] = -1\n",
    "    clust_filt.set_index(['lon', 'lat'], inplace=True)\n",
    "    predictions.set_index(['lon', 'lat'], inplace=True)\n",
    "    predictions.loc[clust_filt.index, 'cluster'] = clust_filt.loc[:, 'cluster']\n",
    "    return predictions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/var/folders/pv/8l65k1dd4wl0_vtr3mydz87w0160hr/T/ipykernel_89276/3073179158.py\", line 11, in predict_zone\n  File \"/Users/m1hawks/seamount_picking/code/smount_predictors/src/SeamountHelp.py\", line 372, in predict\n    predictions = self.model.predict(data) # type: ignore\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/sklearn/pipeline.py\", line 601, in predict\n    return self.steps[-1][1].predict(Xt, **params)\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 800, in predict\n    check_is_fitted(self)\n  File \"/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1661, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     zone_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m zone_pred\n\u001b[0;32m---> 14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_zone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mzone\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlatlons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m nulls \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(predictions), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions):  \u001b[38;5;66;03m# ensure non-overlapping cluster numbers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/swot/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "def predict_zone(zone):\n",
    "    lon = zone[0]\n",
    "    lat = zone[1]\n",
    "    data = SeamountHelp.readAndFilterGRD(data_p, lat, lon)\n",
    "    data = exclude_interface(data, 'interfaces_exclude/vector_feats.xy', threshold=20)\n",
    "    data = data.to_dataframe().reset_index()\n",
    "    if np.all(data['z'] == 0):\n",
    "        data['class'] = 0\n",
    "        data['cluster'] = -1\n",
    "        return data\n",
    "    zone_pred = model.predict(data[['lon', 'lat', 'z']])\n",
    "    return zone_pred\n",
    "\n",
    "predictions = Parallel(n_jobs=-2)(delayed(predict_zone)(zone) for zone in latlons)\n",
    "nulls = np.zeros(len(predictions), dtype=bool)\n",
    "for idx, df in enumerate(predictions):  # ensure non-overlapping cluster numbers\n",
    "    assert isinstance(df, pd.DataFrame)  # assertion for code linter typing features\n",
    "    nulls[idx] = np.all(df['z'].values == 0)\n",
    "    df.loc[df['cluster'] != -1, 'cluster'] = df.loc[df['cluster'] != -1, 'cluster'] + ((idx ** 2) * len(np.unique(df['cluster'])))\n",
    "assert not np.all(nulls)\n",
    "predictions = pd.concat(predictions)\n",
    "predictions = recluster(model, predictions)\n",
    "predictions['lon'] = np.degrees(predictions['lon'])\n",
    "predictions['lat'] = np.degrees(predictions['lat'])\n",
    "predictions = predictions.set_index(['lon', 'lat'])\n",
    "global_predictions = xr.Dataset.from_dataframe(predictions).set_coords(['lon', 'lat']).drop('index')\n",
    "global_predictions.to_netcdf('out/global_predictions.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounts = predictions.groupby('cluster').mean().reset_index()\n",
    "kml = simplekml.Kml()\n",
    "for i, row in mounts.iterrows():\n",
    "    kml.newpoint(name=f'{row.cluster}', coords=[(row.lon, row.lat, row.z)])\n",
    "kml.save('out/global_mounts.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! open out/global_mounts.kml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
