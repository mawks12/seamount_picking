{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from smount_predictors.src.SeamountHelp import PipelinePredictor\n",
    "from smount_predictors import SeamountHelp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplekml\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_pairs = []\n",
    "for lon in range(-180, 180, 20):\n",
    "    longitude_pairs.append((lon, lon + 20))\n",
    "\n",
    "latitude_pairs = []\n",
    "for lat in range(-60, 90, 20):\n",
    "    latitude_pairs.append((lat, lat + 20))\n",
    "\n",
    "\n",
    "latlons = list(product(longitude_pairs, latitude_pairs))\n",
    "latlons = latlons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('out/cluster_tuned_model.pkl', 'rb'))\n",
    "data_p = Path('data/vgg_swot_masked.grd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster(model, predictions):\n",
    "    def filter_clust_size(data: pd.DataFrame):\n",
    "        def circle_ratio(data: pd.DataFrame) -> pd.DataFrame:\n",
    "            circle = abs(data['lat'].max() - data['lat'].min()) / abs(data['lon'].max() - data['lon'].min())\n",
    "            return circle\n",
    "        circle_range = data.copy()\n",
    "        divs = circle_range.groupby('cluster').apply(circle_ratio)\n",
    "        divs = divs[(divs > 1 - np.std(divs)) & (divs < 1 + np.std(divs))]\n",
    "        circle_range = circle_range.loc[(~circle_range['cluster'].isin(divs.index)) & (circle_range['cluster'] != -1)]\n",
    "        return circle_range\n",
    "\n",
    "    def norm_z(data: pd.DataFrame):\n",
    "        data['norm_z'] = (data['z'] - data['z'].min()) / (data['z'].max() - data['z'].min())\n",
    "        return data\n",
    "\n",
    "    clust_filt = predictions.copy()\n",
    "\n",
    "    clust_filt = filter_clust_size(clust_filt)\n",
    "    clust_filt = norm_z(clust_filt)\n",
    "    clust_pred = clust_filt.loc[(clust_filt['cluster'] != -1) & (clust_filt['norm_z'] > 0.5)]\n",
    "\n",
    "\n",
    "    model.clusterer.fit_predict(clust_pred[['lon', 'lat']])\n",
    "    clust_filt.loc[(clust_filt['cluster'] != -1) & (clust_filt['norm_z'] > 0.5), 'cluster'] = model.clusterer.labels_ + predictions['cluster'].max() + 1\n",
    "    clust_filt.loc[~((clust_filt['cluster'] != -1) & (clust_filt['norm_z'] > 0.5)), 'cluster'] = -1\n",
    "    checked = predictions.loc[~predictions.index.isin(clust_filt.index)]\n",
    "    checked = pd.concat([checked, clust_filt])\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_zone(zone):\n",
    "    lon = zone[0]\n",
    "    lat = zone[1]\n",
    "    # print(f'Predicting zone {lon}-{lat}')\n",
    "    data = SeamountHelp.readAndFilterGRD(data_p, lat, lon).to_dataframe().reset_index()\n",
    "    # masked_data = exclude_interface(data).to_dataframe().reset_index()\n",
    "    if np.all(data['z'] == 0):\n",
    "        data['class'] = 0\n",
    "        data['cluster'] = -1\n",
    "        return data\n",
    "    zone_pred = model.predict(data[['lon', 'lat', 'z']])\n",
    "    return zone_pred\n",
    "\n",
    "predictions = Parallel(n_jobs=-1)(delayed(predict_zone)(zone) for zone in latlons)\n",
    "for idx, df in enumerate(predictions):  # ensure non-overlapping cluster numbers\n",
    "    df['cluster'][df['cluster'] != -1] = df['cluster'][df['cluster'] != -1] + ((idx**2) * len(np.unique(df['cluster'])))\n",
    "predictions = pd.concat(predictions)\n",
    "predictions = recluster(model, predictions)\n",
    "predictions['lon'] = np.degrees(predictions['lon'])\n",
    "predictions['lat'] = np.degrees(predictions['lat'])\n",
    "global_predictions = xr.Dataset.from_dataframe(predictions.set_index(['lon', 'lat']))\n",
    "global_predictions.to_netcdf('out/global_predictions.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounts = predictions.groupby('cluster').mean().reset_index()\n",
    "kml = simplekml.Kml()\n",
    "for i, row in mounts.iterrows():\n",
    "    kml.newpoint(name=f'{row.cluster}', coords=[(row.lon, row.lat, row.z)])\n",
    "kml.save('out/global_mounts.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! open out/global_mounts.kml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/all.xyhrdnc', sep=' ', header=None, names=['lon', 'lat', 'z', 'h', 'r', 'd', 'n', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
