{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from smount_predictors.src.SeamountHelp import PipelinePredictor\n",
    "from smount_predictors import SeamountHelp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplekml\n",
    "import xarray as xr\n",
    "from interfaces_exclude.exclude_interface import exclude_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! gmt grdmath dist2coast.grd 20 GE = coast_mask.grd\n",
    "! gmt grdmath depth_mask.grd coast_mask.grd MUL = swot_mask.grd\n",
    "! gmt grdmath swot_mask.grd vgg_swot.grd MUL = swot_landmask.grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_pairs = []\n",
    "for lon in range(-180, 180, 5):\n",
    "    longitude_pairs.append((lon, lon + 5))\n",
    "\n",
    "latitude_pairs = []\n",
    "for lat in range(-80, 80, 5):\n",
    "    latitude_pairs.append((lat, lat + 5))\n",
    "\n",
    "latlons = list(product(longitude_pairs, latitude_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('out/cluster_tuned_model.pkl', 'rb'))\n",
    "data_p = Path('data/swot_landmask.grd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster(model: PipelinePredictor, predictions: pd.DataFrame):\n",
    "    def filter_clust_size(data: pd.DataFrame):\n",
    "        def circle_ratio(data: pd.DataFrame):\n",
    "            if abs(data['lon'].max() - data['lon'].min()) == 0:\n",
    "                return 0\n",
    "            if data.loc[:, 'cluster'].mean() == -1:\n",
    "                return 1\n",
    "            circle = abs(data['lat'].max() - data['lat'].min()) / abs(data['lon'].max() - data['lon'].min())\n",
    "            mass = (abs(data['lat'].max() - data['lat'].min()) * abs(data['lon'].max() - data['lon'].min())) / data.shape[0]\n",
    "            if circle == 0:\n",
    "                return 0\n",
    "            mass = 4 * mass / (circle * np.pi)  # Scale mass to be 1 if it is the correct mass of a circle\n",
    "            return circle * mass\n",
    "        circle_range = data\n",
    "        divs = circle_range.groupby('cluster').apply(circle_ratio)\n",
    "        divs = divs[(divs > np.mean(divs) - np.std(divs)) & (divs < np.mean(divs) + np.std(divs))]\n",
    "        circle_range = circle_range.loc[(~circle_range['cluster'].isin(divs.index)) & (circle_range['cluster'] != -1)]\n",
    "        return circle_range\n",
    "\n",
    "    def norm_z(data: pd.DataFrame):\n",
    "        data['norm_z'] = (data['z'] - data['z'].min()) / (data['z'].max() - data['z'].min())\n",
    "        return data\n",
    "    predictions = predictions.reset_index()\n",
    "    clust_filt = predictions.copy()\n",
    "\n",
    "    clust_filt = filter_clust_size(clust_filt)\n",
    "    clust_filt = norm_z(clust_filt)\n",
    "    recluster_index = (clust_filt['cluster'] != -1) & (clust_filt['norm_z'] > 0.7)\n",
    "    clust_pred = clust_filt.loc[recluster_index]\n",
    "\n",
    "    model.clusterer.fit_predict(clust_pred[['lon', 'lat']])\n",
    "    clust_filt.loc[recluster_index, 'cluster'] = model.clusterer.labels_ + predictions['cluster'].max() + 1\n",
    "    clust_filt.loc[~recluster_index, 'cluster'] = -1\n",
    "    clust_filt.set_index(['lon', 'lat'], inplace=True)\n",
    "    predictions.set_index(['lon', 'lat'], inplace=True)\n",
    "    predictions.loc[clust_filt.index, 'cluster'] = clust_filt.loc[:, 'cluster']\n",
    "    return predictions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/nxggzv_j5s936v9rvl85gh2w0000gn/T/ipykernel_64293/362052295.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  divs = circle_range.groupby('cluster').apply(circle_ratio)\n",
      "/var/folders/v7/nxggzv_j5s936v9rvl85gh2w0000gn/T/ipykernel_64293/3095558326.py:25: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  global_predictions = xr.Dataset.from_dataframe(predictions).set_coords(['lon', 'lat']).drop('index')\n"
     ]
    }
   ],
   "source": [
    "def predict_zone(zone):\n",
    "    lon = zone[0]\n",
    "    lat = zone[1]\n",
    "    data = SeamountHelp.readAndFilterGRD(data_p, lat, lon)\n",
    "    data = exclude_interface(data, 'interfaces_exclude/vector_feats.xy', threshold=20)\n",
    "    data = data.to_dataframe().reset_index()\n",
    "    if np.all(data['z'] == 0):\n",
    "        data['class'] = 0\n",
    "        data['cluster'] = -1\n",
    "        return data\n",
    "    zone_pred = model.predict(data[['lon', 'lat', 'z']])\n",
    "    return zone_pred\n",
    "\n",
    "predictions = Parallel(n_jobs=-3)(delayed(predict_zone)(zone) for zone in latlons)\n",
    "nulls = np.zeros(len(predictions), dtype=bool)\n",
    "for idx, df in enumerate(predictions):  # ensure non-overlapping cluster numbers\n",
    "    assert isinstance(df, pd.DataFrame)  # assertion for code linter typing features\n",
    "    nulls[idx] = np.all(df['z'].values == 0)\n",
    "    df.loc[df['cluster'] != -1, 'cluster'] = df.loc[df['cluster'] != -1, 'cluster'] + ((idx ** 2) * len(np.unique(df['cluster'])))\n",
    "assert not np.all(nulls)\n",
    "predictions = pd.concat(predictions)\n",
    "predictions = recluster(model, predictions)\n",
    "predictions['lon'] = np.degrees(predictions['lon'])\n",
    "predictions['lat'] = np.degrees(predictions['lat'])\n",
    "global_predictions = xr.Dataset.from_dataframe(predictions).set_coords(['lon', 'lat']).drop('index')\n",
    "global_predictions.to_netcdf('out/global_predictions.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounts = predictions.groupby('cluster').mean().reset_index()\n",
    "kml = simplekml.Kml()\n",
    "for i, row in mounts.iterrows():\n",
    "    kml.newpoint(name=f'{row.cluster}', coords=[(row.lon, row.lat, row.z)])\n",
    "kml.save('out/global_mounts.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! open out/global_mounts.kml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
